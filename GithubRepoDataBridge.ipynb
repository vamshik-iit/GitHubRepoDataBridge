{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0e2fcc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the required packages\n",
    "import pandas as pd\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import datetime\n",
    "import time\n",
    "from datetime import timedelta\n",
    "from datetime import datetime\n",
    "import json\n",
    "import requests\n",
    "import edgedb\n",
    "\n",
    "import warnings\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import dateutil.relativedelta\n",
    "from dateutil import *\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime as dt\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8cf9af73",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = edgedb.create_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "40947d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = os.environ.get('GITHUB_TOKEN', '')\n",
    "GITHUB_URL = f\"https://api.github.com/\"\n",
    "headers = {\"Authorization\": f'token {token}'}\n",
    "params = {\"state\": \"open\"}\n",
    "today = date.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ff8b7e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetchweekdata(repo_name):\n",
    "    data = {}\n",
    "    issues_reponse = []\n",
    "    for i in range(1):\n",
    "        today = date.today()\n",
    "        last_month = today + dateutil.relativedelta.relativedelta(weeks=-1)\n",
    "        print('Today date ', today)\n",
    "        print('Last Week date ', last_month)\n",
    "        types = 'type:issue'\n",
    "        repo = 'repo:' + repo_name\n",
    "        ranges = 'created:' + str(last_month) + '..' + str(today)\n",
    "        per_page = 'per_page=100'\n",
    "        search_query = types + ' ' + repo + ' ' + ranges\n",
    "        query_url = GITHUB_URL + \"search/issues?q=\" + search_query + \"&\" + per_page\n",
    "        search_issues = requests.get(query_url, headers=headers, params=params)\n",
    "        search_issues = search_issues.json()\n",
    "        issues_items = []\n",
    "        try:\n",
    "            issues_items = search_issues.get(\"items\")\n",
    "        except KeyError:\n",
    "            error = {\"error\": \"Data Not Available\"}\n",
    "            resp = Response(json.dumps(error), mimetype='application/json')\n",
    "            resp.status_code = 500\n",
    "            return resp\n",
    "        if issues_items is None:\n",
    "            continue\n",
    "        for issue in issues_items:\n",
    "            label_name = []\n",
    "            \n",
    "            current_issue = issue\n",
    "            data['issue_number'] = current_issue[\"number\"]\n",
    "            data['created_at'] = current_issue[\"created_at\"][0:10]\n",
    "            if current_issue[\"closed_at\"] == None:\n",
    "                data['closed_at'] = current_issue[\"closed_at\"]\n",
    "            else:\n",
    "                data['closed_at'] = current_issue[\"closed_at\"][0:10]\n",
    "            for label in current_issue[\"labels\"]:\n",
    "                label_name.append(label[\"name\"])\n",
    "            data['labels'] = label_name\n",
    "            data['State'] = current_issue[\"state\"]\n",
    "            data['Author'] = current_issue[\"user\"][\"login\"]\n",
    "            issues_reponse.append(data)\n",
    "        today = last_month\n",
    "    return issues_reponse\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e1128d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertdatetime(inpdate):\n",
    "    try:\n",
    "        unix_timestamp = int(inpdate)\n",
    "        return unix_timestamp\n",
    "    except ValueError:\n",
    "        try:\n",
    "            datetime_object = datetime.strptime(inpdate, \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "            unix_timestamp = int(datetime_object.timestamp())\n",
    "            return unix_timestamp\n",
    "        except ValueError:\n",
    "            print(f\"Invalid date format: {inpdate}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8dcdb347",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def convert_to_datetime(date_input):\n",
    "    try:\n",
    "        unix_timestamp = int(date_input)\n",
    "        datetime_object = datetime.utcfromtimestamp(unix_timestamp)\n",
    "        return str(datetime_object)[0:10]\n",
    "    except ValueError:\n",
    "        try:\n",
    "            datetime_object = datetime.strptime(date_input, \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "            return str(datetime_object)[0:10]\n",
    "        except ValueError:\n",
    "            print(f\"Invalid date format: {date_input}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3c69c64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetchyeardata(repo_name,nummonths,weekormonth):\n",
    "    print(\"********\",repo_name,\"********\")\n",
    "    data = {}\n",
    "    issues_reponse = []\n",
    "    last_month=''\n",
    "    for i in range(nummonths):\n",
    "        today = date.today()\n",
    "        if(weekormonth == 'w'):\n",
    "            last_month = today + dateutil.relativedelta.relativedelta(weeks=-1)\n",
    "        else:\n",
    "            last_month = today + dateutil.relativedelta.relativedelta(months=-1)\n",
    "        types = 'type:issue'\n",
    "        repo = 'repo:' + repo_name\n",
    "        ranges = 'created:' + str(last_month) + '..' + str(today)\n",
    "        per_page = 'per_page=100'\n",
    "        search_query = types + ' ' + repo + ' ' + ranges\n",
    "        query_url = GITHUB_URL + \"search/issues?q=\" + search_query + \"&\" + per_page\n",
    "        search_issues = requests.get(query_url, headers=headers, params=params)\n",
    "        search_issues = search_issues.json()\n",
    "        issues_items = []\n",
    "        max_date = dt.strptime(str(today + dateutil.relativedelta.relativedelta(months=-nummonths)), \"%Y-%m-%d\")\n",
    "        try:\n",
    "            issues_items = search_issues.get(\"items\")\n",
    "        except KeyError:\n",
    "            error = {\"error\": \"Data Not Available\"}\n",
    "            resp = Response(json.dumps(error), mimetype='application/json')\n",
    "            resp.status_code = 500\n",
    "            return resp\n",
    "        if issues_items is None:\n",
    "            continue\n",
    "        for issue in issues_items:\n",
    "            label_name = []\n",
    "            current_issue = issue\n",
    "            #res_date = dt.strptime(current_issue[\"created_at\"][0:10], \"%Y-%m-%d\")\n",
    "            tmp = convert_to_datetime(current_issue[\"created_at\"])\n",
    "            res_date=dt.strptime(tmp, \"%Y-%m-%d\")\n",
    "            #print(res_date)\n",
    "            #print(type(res_date))\n",
    "            if res_date > max_date:         \n",
    "                data['repo_name'] = repo_name\n",
    "                data['issue_number'] = current_issue[\"number\"]\n",
    "                title = current_issue[\"title\"]\n",
    "                cleaned_title = re.sub(r'[^A-Za-z0-9\\s]', '', title)\n",
    "                data['title']=cleaned_title\n",
    "                data['created_at'] =convertdatetime(current_issue[\"created_at\"])\n",
    "\n",
    "                if current_issue[\"closed_at\"] == None:\n",
    "                    data['closed_at'] = 0\n",
    "                else:\n",
    "                    data['closed_at'] = convertdatetime(current_issue[\"closed_at\"])\n",
    "\n",
    "                if current_issue[\"updated_at\"] == None:\n",
    "                    data['updated_at'] = 0\n",
    "                else:\n",
    "                    data['updated_at'] = convertdatetime(current_issue[\"updated_at\"])\n",
    "\n",
    "                for label in current_issue[\"labels\"]:\n",
    "                    label_name.append(label[\"name\"])\n",
    "\n",
    "                data['labels'] = label_name\n",
    "                data['State'] = current_issue[\"state\"]\n",
    "                data['locked']=current_issue[\"locked\"]\n",
    "                data['Author'] = current_issue[\"user\"][\"login\"]\n",
    "                data['state_reason']=current_issue[\"state_reason\"]\n",
    "                data['score']=current_issue[\"score\"]\n",
    "                issues_reponse.append(data)\n",
    "        today = last_month\n",
    "    return issues_reponse\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c1b20db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insertData(data):\n",
    "    for user_data in data:\n",
    "        client.query(\"\"\"\n",
    "                INSERT RepoData{\n",
    "                    repo_name := <str>$repo_name,\n",
    "                    issue_number := <int32>$issue_number,\n",
    "                    title := <str>$title,\n",
    "                    created_at := to_datetime(<bigint>$created_at),\n",
    "                    closed_at := to_datetime(<bigint>$closed_at),\n",
    "                    updated_at := to_datetime(<bigint>$updated_at),\n",
    "                    labels := <str>$labels,\n",
    "                    State := <str>$State,\n",
    "                    locked := <str>$locked,\n",
    "                    Author := <str>$Author,\n",
    "                    state_reason :=<str>$state_reason,\n",
    "                    score := <str>$score\n",
    "                    \n",
    "                } \"\"\", \n",
    "                repo_name=str(user_data.get('repo_name', '')),\n",
    "                issue_number=int(user_data.get('issue_number', 0)),\n",
    "                title=str(user_data.get('title', '')) ,\n",
    "                created_at=int(user_data.get('created_at', 0)) ,\n",
    "                closed_at=int(user_data.get('closed_at', 0)),\n",
    "                updated_at=int(user_data.get('updated_at', 0)),\n",
    "                labels=str(user_data.get('labels', '')),\n",
    "                State=str(user_data.get('State','')),\n",
    "                locked=str(user_data.get('locked', '')),\n",
    "                Author=str(user_data.get('Author', '')),\n",
    "                state_reason=str(user_data.get('state_reason', '')),\n",
    "                score=str(user_data.get('score', ''))\n",
    "                );\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4f669308-4dfd-46a2-b3c0-f8668817818e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insertCommitsData(data):\n",
    "    for user_data in data:\n",
    "        client.query(\"\"\"\n",
    "                INSERT CommitsData{\n",
    "                    repo_name := <str>$repo_name,\n",
    "                    commit_number := <int32>$commit_number,\n",
    "                    created_at := to_datetime(<bigint>$created_at)\n",
    "                } \"\"\",\n",
    "                repo_name=str(user_data.get('repo_name', '')),\n",
    "                commit_number=int(user_data.get('commit_number', 0)),\n",
    "                created_at=int(user_data.get('created_at', 0)) \n",
    "                );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5028a8cb-adba-4e4a-ba8a-2bd9a044ebcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insertPullsData(data):\n",
    "    for user_data in data:\n",
    "        client.query(\"\"\"\n",
    "                INSERT PullsData{\n",
    "                    repo_name := <str>$repo_name,\n",
    "                    pull_req_number := <int32>$pull_req_number,\n",
    "                    created_at := to_datetime(<bigint>$created_at),\n",
    "                    closed_at := to_datetime(<bigint>$closed_at),\n",
    "                    labels := <str>$labels,\n",
    "                    State := <str>$State,\n",
    "                    Author := <str>$Author\n",
    "                    \n",
    "                } \"\"\",\n",
    "                repo_name=str(user_data.get('repo_name', '')),\n",
    "                pull_req_number=int(user_data.get('pull_req_number', 0)),\n",
    "                created_at=int(user_data.get('created_at', 0)) ,\n",
    "                closed_at=int(user_data.get('closed_at', 0)),\n",
    "                labels=str(user_data.get('labels', '')),\n",
    "                State=str(user_data.get('State','')),\n",
    "                Author=str(user_data.get('Author', ''))\n",
    "                );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "93fc3653-7c94-4543-850d-0d73dcf384cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getcommitsdata(repo_name):\n",
    "    n=0\n",
    "    reponse = []\n",
    "    for i in range(60):\n",
    "        per_page = 'per_page=100'\n",
    "        page = 'page='\n",
    "        search_query = per_page+ \"&\" + page + f'{i}'\n",
    "        #repo_name = 'angular/angular'\n",
    "        query_url = GITHUB_URL + \"repos/\" + repo_name + \"/commits?\" + search_query\n",
    "        #print(query_url)\n",
    "        search_commits = requests.get(query_url, headers=headers, params=params)\n",
    "        search_commits = search_commits.json()\n",
    "        commits_items = []\n",
    "        commits_items = search_commits\n",
    "        if commits_items is None:\n",
    "            continue\n",
    "        for commit_req in commits_items:\n",
    "            label_name = []\n",
    "            data = {}\n",
    "            current_commit = commit_req\n",
    "            created_at_date = dt.strptime(current_commit[\"commit\"][\"committer\"][\"date\"][0:10], \"%Y-%m-%d\")\n",
    "            max_date = dt.strptime(\"2023-11-19\", \"%Y-%m-%d\")\n",
    "            if created_at_date > max_date:\n",
    "                n=n+1\n",
    "                data['repo_name'] = repo_name\n",
    "                data['commit_number'] = n\n",
    "                data['created_at'] = convertdatetime(current_commit[\"commit\"][\"committer\"][\"date\"]) \n",
    "                reponse.append(data)\n",
    "    return reponse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "aa1bcce6-51a4-499d-bdad-bb2f6efd1515",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getpullsdata(repo_name):\n",
    "    reponse = []\n",
    "    for i in range(24):\n",
    "        per_page = 'per_page=100'\n",
    "        page = 'page='\n",
    "        search_query = repo_name + '/pulls?state=all' + \"&\" + per_page+ \"&\" + page + f'{i}'\n",
    "        GITHUB_URL = f\"https://api.github.com/\"\n",
    "        query_url = GITHUB_URL + \"repos/\" + search_query\n",
    "        search_pull_requests = requests.get(query_url, headers=headers, params=params)\n",
    "        search_pull_requests = search_pull_requests.json()\n",
    "        pull_items = []\n",
    "        pull_items = search_pull_requests\n",
    "        if pull_items is None:\n",
    "            continue\n",
    "        for pull_req in pull_items:\n",
    "            label_name = []\n",
    "            data = {}\n",
    "            current_pull_req = pull_req\n",
    "            created_at_date = dt.strptime(current_pull_req[\"created_at\"][0:10], \"%Y-%m-%d\")\n",
    "            max_date = dt.strptime(\"2023-11-19\", \"%Y-%m-%d\")\n",
    "            if created_at_date > max_date:\n",
    "                data['repo_name'] = repo_name\n",
    "                data['pull_req_number'] = current_pull_req[\"number\"]\n",
    "                data['created_at'] = convertdatetime(current_pull_req[\"created_at\"])\n",
    "                if current_pull_req[\"closed_at\"] == None:\n",
    "                    data['closed_at'] = 0\n",
    "                else:\n",
    "                    data['closed_at'] = convertdatetime(current_pull_req[\"closed_at\"])\n",
    "                for label in current_pull_req[\"labels\"]:\n",
    "                    label_name.append(label[\"name\"])\n",
    "                data['labels'] = label_name\n",
    "                data['State'] = current_pull_req[\"state\"]\n",
    "                data['Author'] = current_pull_req[\"user\"][\"login\"]\n",
    "                reponse.append(data)\n",
    "    return reponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "fcf35943-6347-446d-924b-ed1bef1afc88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************* 1 week data processing ********************** \n",
      "******** facebook/react ********\n",
      "Processed for facebook/react, time to complete  70.91370368003845 seconds\n",
      "******** SeleniumHQ/selenium ********\n",
      "Processed for facebook/react, time to complete  55.3511164188385 seconds\n",
      "******** python/cpython ********\n",
      "Processed for facebook/react, time to complete  121.30441737174988 seconds\n",
      "******** keras-team/keras ********\n",
      "Processed for facebook/react, time to complete  50.64165234565735 seconds\n",
      "******** openai/openai-node ********\n",
      "Processed for facebook/react, time to complete  40.53581142425537 seconds\n",
      "******** docker/docker ********\n",
      "Processed for facebook/react, time to complete  85.93197083473206 seconds\n",
      "******** milvus-io/milvus ********\n",
      "Processed for facebook/react, time to complete  68.15482902526855 seconds\n",
      "************************* 1 week data processing completed ********************** \n"
     ]
    }
   ],
   "source": [
    "repositories = ['facebook/react', 'SeleniumHQ/selenium', 'python/cpython', 'keras-team/keras', 'openai/openai-node', 'docker/compose', 'milvus-io/milvus']\n",
    "print(\"************************* 1 week data processing ********************** \")\n",
    "for repo in repositories:\n",
    "    start_time = time.time()\n",
    "    repo_data=fetchyeardata(repo,1,'w')\n",
    "    insertData(repo_data)\n",
    "    commits_data=getcommitsdata(repo)\n",
    "    insertCommitsData(commits_data)\n",
    "    pulls_data = getpullsdata(repo)\n",
    "    insertPullsData(pulls_data)\n",
    "    print(\"Processed for facebook/react, time to complete \", time.time() - start_time, \"seconds\")\n",
    "    time.sleep(15)\n",
    "print(\"************************* 1 week data processing completed ********************** \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8821c739-de06-4788-b834-2b4106f41e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#One month data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6e45ec12-ba15-405c-a4b7-7e705c66041d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************* 1 month data processing ********************** \n",
      "******** facebook/react ********\n",
      "Count =  60\n",
      "Processed for facebook/react, time to complete  1.2666659355163574 seconds\n",
      "******** SeleniumHQ/selenium ********\n",
      "Count =  98\n",
      "Processed for facebook/react, time to complete  2.2910115718841553 seconds\n",
      "******** python/cpython ********\n",
      "Count =  100\n",
      "Processed for facebook/react, time to complete  1.5370512008666992 seconds\n",
      "******** keras-team/keras ********\n",
      "Count =  41\n",
      "Processed for facebook/react, time to complete  1.0314946174621582 seconds\n",
      "******** openai/openai-node ********\n",
      "Count =  60\n",
      "Processed for facebook/react, time to complete  0.9772868156433105 seconds\n",
      "******** docker/compose ********\n",
      "Count =  38\n",
      "Processed for facebook/react, time to complete  0.9340412616729736 seconds\n",
      "******** milvus-io/milvus ********\n",
      "Count =  100\n",
      "Processed for facebook/react, time to complete  1.5778892040252686 seconds\n",
      "************************* 1 month data processing completed ********************** \n"
     ]
    }
   ],
   "source": [
    "repositories = ['facebook/react', 'SeleniumHQ/selenium', 'python/cpython', 'keras-team/keras', 'openai/openai-node', 'docker/compose', 'milvus-io/milvus']\n",
    "print(\"************************* 1 month data processing ********************** \")\n",
    "for repo in repositories:\n",
    "    start_time = time.time()\n",
    "    repo_data=fetchyeardata(repo,1,'m')\n",
    "    print(\"Count = \", len(repo_data))\n",
    "    insertData(repo_data)\n",
    "    print(\"Processed for facebook/react, time to complete \", time.time() - start_time, \"seconds\")\n",
    "    time.sleep(15)\n",
    "print(\"************************* 1 month data processing completed ********************** \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82972bb9-3dfc-4484-b31b-3c6e70b95aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#One year data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "30556fe7-bb27-450d-b03d-d8eeb720c434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******** facebook/react ********\n",
      "768\n",
      "Processed for facebook/react, time to complete  13.646721363067627 seconds\n",
      "******** SeleniumHQ/selenium ********\n",
      "1200\n",
      "Processed for SeleniumHQ/selenium, time to complete  17.5732524394989 seconds\n",
      "******** python/cpython ********\n",
      "1200\n",
      "Processed for openai/openai-quickstart-python, time to complete  18.20203447341919 seconds\n",
      "******** keras-team/keras ********\n",
      "540\n",
      "Processed for keras-team/keras, time to complete  11.68669080734253 seconds\n",
      "******** openai/openai-node ********\n",
      "720\n",
      "Processed for openai/openai-node, time to complete  12.723157167434692 seconds\n",
      "******** docker/compose ********\n",
      "480\n",
      "Processed for docker/compose, time to complete  11.140951156616211 seconds\n",
      "******** milvus-io/milvus ********\n",
      "1200\n",
      "Processed for milvus-io/milvus, time to complete  18.4046847820282 seconds\n",
      "************************* process completed *****************************\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "reactdata = fetchyeardata('facebook/react',12,'m')\n",
    "print(len(reactdata))\n",
    "insertData(reactdata)\n",
    "print(\"Processed for facebook/react, time to complete \", time.time() - start_time, \"seconds\")\n",
    "\n",
    "time.sleep(15)\n",
    "start_time = time.time()\n",
    "seleniumdata = fetchyeardata('SeleniumHQ/selenium',12,'m')\n",
    "print(len(seleniumdata))\n",
    "insertData(seleniumdata)\n",
    "print(\"Processed for SeleniumHQ/selenium, time to complete \", time.time() - start_time, \"seconds\")\n",
    "\n",
    "time.sleep(15)\n",
    "start_time = time.time()\n",
    "pythondata = fetchyeardata('python/cpython',12,'m')\n",
    "print(len(pythondata))\n",
    "insertData(pythondata)\n",
    "print(\"Processed for openai/openai-quickstart-python, time to complete \", time.time() - start_time, \"seconds\")\n",
    "\n",
    "time.sleep(15)\n",
    "start_time = time.time()\n",
    "kerasdata = fetchyeardata('keras-team/keras',12,'m')\n",
    "print(len(kerasdata))\n",
    "insertData(kerasdata)\n",
    "print(\"Processed for keras-team/keras, time to complete \", time.time() - start_time, \"seconds\")\n",
    "\n",
    "time.sleep(15)\n",
    "start_time = time.time()\n",
    "nodedata = fetchyeardata('openai/openai-node',12,'m')\n",
    "print(len(nodedata))\n",
    "insertData(nodedata)\n",
    "print(\"Processed for openai/openai-node, time to complete \", time.time() - start_time, \"seconds\")\n",
    "\n",
    "time.sleep(15)\n",
    "start_time = time.time()\n",
    "composedata = fetchyeardata('docker/compose',12,'m')\n",
    "print(len(composedata))\n",
    "insertData(composedata)\n",
    "print(\"Processed for docker/compose, time to complete \", time.time() - start_time, \"seconds\")\n",
    "\n",
    "time.sleep(15)\n",
    "start_time = time.time()\n",
    "milvusdata = fetchyeardata('milvus-io/milvus',12,'m')\n",
    "print(len(milvusdata))\n",
    "insertData(milvusdata)\n",
    "print(\"Processed for milvus-io/milvus, time to complete \", time.time() - start_time, \"seconds\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"************************* process completed *****************************\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d06d257e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12276\n",
      "Object{id := UUID('9399b4d0-8b9f-11ee-bd4e-23ca9d50269d'), repo_name := 'facebook/react', issue_number := 27602, title := 'Ability to turn off Download DevTools console message', created_at := datetime.datetime(2023, 10, 27, 7, 13, 41, tzinfo=datetime.timezone.utc), closed_at := datetime.datetime(1970, 1, 1, 0, 0, tzinfo=datetime.timezone.utc), updated_at := datetime.datetime(2023, 10, 30, 23, 35, 5, tzinfo=datetime.timezone.utc), labels := \"['Status: Unconfirmed']\", State := 'open', locked := 'False', Author := 'rmschindler', state_reason := 'None', score := '1.0'}\n"
     ]
    }
   ],
   "source": [
    "import edgedb\n",
    "\n",
    "edgedbdata = client.query(\"SELECT RepoData {id,repo_name,issue_number,title,created_at,closed_at,updated_at,labels,State,locked,Author,state_reason,score}\");\n",
    "print(len(edgedbdata))\n",
    "print(edgedbdata[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c2909033",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import connections, utility, FieldSchema, Collection, CollectionSchema, DataType\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "10074fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connects to a server:\n",
    "connections.connect(\"default\", host=\"localhost\", port=\"19530\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "62342218-1053-4515-8327-e1ea3ce4a708",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "HOST = 'localhost'\n",
    "PORT = 19530\n",
    "COLLECTION_NAME = 'repo'\n",
    "DIMENSION = 1536\n",
    "OPENAI_ENGINE = 'text-embedding-ada-002'\n",
    "openai.api_key = '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'\n",
    "\n",
    "INDEX_PARAM = {\n",
    "    'metric_type':'L2',\n",
    "    'index_type':\"HNSW\",\n",
    "    'params':{'M': 8, 'efConstruction': 64}\n",
    "}\n",
    "\n",
    "QUERY_PARAM = {\n",
    "    \"metric_type\": \"L2\",\n",
    "    \"params\": {\"ef\": 64},\n",
    "}\n",
    "\n",
    "BATCH_SIZE = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "59252f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import connections, utility, FieldSchema, Collection, CollectionSchema, DataType\n",
    "\n",
    "# Connect to Milvus Database\n",
    "connections.connect(host=HOST, port=PORT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "aefef58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove collection if it already exists\n",
    "if utility.has_collection(COLLECTION_NAME):\n",
    "    utility.drop_collection(COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "604f6f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields_repo_data = [\n",
    "    FieldSchema(name=\"id\", dtype=DataType.INT64, is_primary=True, auto_id=True),\n",
    "    FieldSchema(name=\"repo_name\", dtype=DataType.VARCHAR, max_length=64000),\n",
    "    FieldSchema(name=\"issue_number\", dtype=DataType.INT32),\n",
    "    FieldSchema(name=\"title\", dtype=DataType.VARCHAR, max_length=64000),\n",
    "    FieldSchema(name=\"created_at\", dtype=DataType.VARCHAR, max_length=64000),\n",
    "    FieldSchema(name=\"closed_at\", dtype=DataType.VARCHAR, max_length=64000),\n",
    "    FieldSchema(name=\"updated_at\", dtype=DataType.VARCHAR, max_length=64000),\n",
    "    FieldSchema(name=\"labels\", dtype=DataType.VARCHAR, max_length=64000),\n",
    "    FieldSchema(name=\"state\", dtype=DataType.VARCHAR, max_length=64000),\n",
    "    FieldSchema(name=\"locked\", dtype=DataType.VARCHAR, max_length=64000),\n",
    "    FieldSchema(name=\"author\", dtype=DataType.VARCHAR, max_length=64000),\n",
    "    FieldSchema(name=\"state_reason\", dtype=DataType.VARCHAR, max_length=64000),\n",
    "    FieldSchema(name=\"score\", dtype=DataType.VARCHAR, max_length=64000),\n",
    "    FieldSchema(name=\"embeddings\", dtype=DataType.FLOAT_VECTOR, dim=DIMENSION),\n",
    "]\n",
    "schema = CollectionSchema(fields=fields_repo_data)\n",
    "collection = Collection(name=COLLECTION_NAME, schema=schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "212333a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the index on the collection and load it.\n",
    "collection.create_index(field_name=\"embeddings\", index_params=INDEX_PARAM)\n",
    "collection.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "4026a591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple function that converts the texts to embeddings\n",
    "#from openai import OpenAI\n",
    "#client = OpenAI(api_key='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')\n",
    "'''\n",
    "def embed(text):\n",
    "    model=\"text-embedding-ada-002\"\n",
    "    return openai.embeddings.create(input = [text], model=model)['data'][0]['embedding']\n",
    "'''\n",
    "from openai import OpenAI\n",
    "def embed(text):\n",
    "    model=\"text-embedding-ada-002\"\n",
    "    return openai.embeddings.create(input = [text], model=model)['data'][0]['embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "4164d164",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "data = [\n",
    "    [], # repo_name\n",
    "    [], # issue_number\n",
    "    [], # title\n",
    "    [], # created_at\n",
    "    [], # closed_at\n",
    "    [], # updated_at\n",
    "    [], # labels\n",
    "    [], # State\n",
    "    [], # locked\n",
    "    [], # Author\n",
    "    [], # state_reason\n",
    "    [], # score\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "e3735388-0018-4d0b-b1d6-b46734d6f9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12276/12276 [00:00<00:00, 420245.15it/s]\n"
     ]
    }
   ],
   "source": [
    "# Embed and insert in batches\n",
    "for i in tqdm(range(0, len(edgedbdata))):\n",
    "    data[0].append(edgedbdata[i].repo_name or '')\n",
    "    data[1].append(edgedbdata[i].issue_number or 0)\n",
    "    data[2].append(edgedbdata[i].title or '')\n",
    "    data[3].append(edgedbdata[i].created_at or '')\n",
    "    data[4].append(edgedbdata[i].closed_at or '')\n",
    "    data[5].append(edgedbdata[i].updated_at or '')\n",
    "    data[6].append(edgedbdata[i].labels or '')\n",
    "    data[7].append(edgedbdata[i].State or '')\n",
    "    data[8].append(edgedbdata[i].locked or '')\n",
    "    data[9].append(edgedbdata[i].Author or '')\n",
    "    data[10].append(edgedbdata[i].state_reason or '')\n",
    "    data[11].append(edgedbdata[i].score or '')\n",
    "    \n",
    "    if len(data[0]) % BATCH_SIZE == 0:\n",
    "        data.append(embed(data[2]))\n",
    "        collection.insert(data)\n",
    "        data = [[],[],[],[],[],[],[],[],[],[],[],[]]\n",
    "\n",
    "# Embed and insert the remainder \n",
    "if len(data[0]) != 0:\n",
    "    data.append(embed(data[1]))\n",
    "    collection.insert(data)\n",
    "    data = [[],[],[],[],[],[],[],[],[],[],[],[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28ea143-92a2-4a8a-8a43-0ff936767a76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
